tla <- 'CEA'
if (!dir.exists(tla)) dir.create(tla)
setwd(paste0('C:/Users/dxsb43/GitHub/Partitioning_Strategies/mutations/', tla))
setwd(paste0('C:/Users/dxsb43/GitHub/Partitioning_Strategies/mutations/CEA'))
setwd('C:/Users/dxsb43/GitHub/Partitioning_Strategies/mutations/CEA')
setwd(paste0('C:/local/dxsb43/GitHub/Partitioning_Strategies/mutations/', tla))
File <- function (suffix) paste0(tla, '/', tla, suffix)
Chain <- function (Func, oTree) {
ret <- vector('list', 500)
for (i in reps) {
oTree <- Func(oTree)
ret[[i]] <- oTree
}
structure(ret, class='multiPhylo')
}
if (!dir.exists(paste0(tla, 'test'))) dir.create(paste0(tla, 'test'))
setwd(paste0('C:/local/dxsb43/GitHub/Partitioning_Strategies/mutations/', tla, 'test'))
setwd(paste0('C:/local/dxsb43/GitHub/Partitioning_Strategies/mutations/', tla))
if (!dir.exists(paste0(tla, 'test'))) dir.create(paste0(tla, 'test'))
inputTree <- read.nexus(paste0(tla, '_optimal_tree.nex'))
inputTree$edge.length <- NULL
inputLabels <- inputTree$tip.label
plot(inputTree)
reps <- seq_len(500)
write.nexus(structure(lapply(reps, function (i)
ape::rtree(n = length(inputLabels), br=NULL, tip.label = inputLabels)),
class='multiPhylo'), file=File('_random.nex'))
CImat <- matrix(, nrow=500, ncol=nChar)
colnames(CImat) <- chars
#which trees to calculate CI for
trees <- read.nexus(paste0('StartingTrees/', datasetName, '_random500.nex')) # reads all 500 random trees
for (i in seq_along(trees)) {
tree <- trees[[i]]
parsScore <- Fitch(tree, dataset)
#calculate number to go in exp() for branch lengths prior
expVal <- ncol(tab)/parsScore
obsSteps <- FitchSteps(tree, dataset)
#calculate Goloboff's unbiased measure of homoplasy for a given k (concavity constant) and data set
k <- 3
f <- (k+1)/(obsSteps+k+1+minSteps)
CImat[i, ] <- f     #fill ith row with the vector of CIs
}
#reshape CImat into long format
CImat <- as.data.frame(CImat)
CImat <- gather(CImat, key="character", value="CI", 1:nChar)
ggplot(CImat, aes(character,CI )) +
geom_violin() +
scale_x_discrete(limits=c(1:50))
ggplot(CImat, aes(character,CI )) +
geom_point() +
scale_x_discrete(limits=c(1:50))
ggplot(CImat, aes(character,CI )) +
geom_scatter() +
scale_x_discrete(limits=c(1:50))
ggplot(CImat, aes(character,CI )) +
geom_jitter() +
scale_x_discrete(limits=c(1:50))
ggplot(CImat, aes(character,CI )) +
geom_jitter(alpha=0.3) +
scale_x_discrete(limits=c(1:50))
ggplot(CImat, aes(character,CI )) +
#  geom_jitter(alpha=0.3) +
scale_x_discrete(limits=c(1:50)) +
stat_binhex()
require(hexbin)
install.packages("hexbin")
require(hexbin)
ggplot(CImat, aes(character,CI )) +
#  geom_jitter(alpha=0.3) +
scale_x_discrete(limits=c(1:50)) +
stat_binhex()
ggplot(CImat, aes(character,CI )) +
#  geom_jitter(alpha=0.3) +
scale_x_discrete(limits=c(1:50)) +
stat_bin2d()
ggplot(CImat, aes(character,CI )) +
#  geom_jitter(alpha=0.3) +
scale_x_discrete(limits=c(1:50)) +
stat_bin_2d()
ggplot(CImat, aes(character,CI )) +
#  geom_jitter(alpha=0.3) +
scale_x_discrete(limits=c(1:50)) +
stat_bin_2d(drop=TRUE)
ggplot(CImat, aes(character,CI )) +
geom_jitter(alpha=0.3) +
scale_x_discrete(limits=c(1:50)) +
stat_bin_2d()
ggplot(CImat, aes(character,CI )) +
#  geom_jitter(alpha=0.3) +
scale_x_discrete(limits=c(1:50)) +
stat_bin_2d()
ggplot(CImat, aes(character,CI )) +
#  geom_jitter(alpha=0.3) +
scale_x_discrete() +
stat_bin_2d()
CImat$facet <- rep(c(1:4),times=50)
#calculate consistency indices (CI) for each character over a set of random trees
require(TreeSearch)
require(ape)
require(phangorn)
require(ggplot2)
require(tidyr)
require(hexbin)
# Select dataset
datasetName <- "CEA"
rootDir <- paste0("C:/local/dxsb43/GitHub/Partitioning_Strategies/mutations/", datasetName)
setwd(rootDir)
mrBayesTemplateFile <- paste0(rootDir, '/', datasetName, '_TEMPLATE.nex')
dataset <- ReadAsPhyDat(mrBayesTemplateFile)
powerOf2 <- 2^(0:ncol(attr(dataset, "contrast"))) #contrast shows the possible permutations of
#the character states, i.e. 0, 1, 2, 3, {01}, {02} etc.
decode <- apply(attr(dataset, "contrast"), 1, function(r)
sum(powerOf2[as.logical(r)])
)
tab <- t(vapply(dataset, I, dataset[[1]])) # translates lists of taxa and character data into matrix
tab <- tab[, attr(dataset, 'index')]
nChar <- ncol(tab)
chars <- seq_len(nChar)
minSteps <- apply(tab, 2, function(char)
TreeSearch:::MinimumSteps(decode[char])
)
CImat <- matrix(, nrow=500, ncol=nChar)
#calculate homoplasy indices from starting trees
require(TreeSearch)
require(ape)
require(phangorn)
# Define constants
nPart <- 4 #number of partitions
prop <- 1/nPart # proportion of characters per partition
insertionComment <- "INSERT PARTITIONS HERE"
bayesFilesDir <- 'MrBayes'
# Select dataset
datasetName <- "SCO"
rootDir <- paste0("C:/local/dxsb43/GitHub/Partitioning_Strategies/mutations/", datasetName)
setwd(rootDir)
mrBayesTemplateFile <- paste0(rootDir, '/', datasetName, '_TEMPLATE.nex')
dataset <- ReadAsPhyDat(mrBayesTemplateFile)
# Mr Bayes template
mrBayesTemplate <- readLines(mrBayesTemplateFile)
mrBayesTemplateFile <- paste0(rootDir, '/', datasetName, '_TEMPLATE.nex')
dataset <- ReadAsPhyDat(mrBayesTemplateFile)
# Mr Bayes template
mrBayesTemplate <- readLines(mrBayesTemplateFile)
insertLine <- grep(insertionComment, mrBayesTemplate)
if (!dir.exists(bayesFilesDir)) dir.create(bayesFilesDir)
powerOf2 <- 2^(0:ncol(attr(dataset, "contrast"))) #contrast shows the possible permutations of
#the character states, i.e. 0, 1, 2, 3, 4, 5, {01}, {02} etc.
decode <- apply(attr(dataset, "contrast"), 1, function(r) #
sum(powerOf2[as.logical(r)])
)
tab <- t(vapply(dataset, I, dataset[[1]])) # translates lists of taxa and character data into matrix
tab <- tab[, attr(dataset, 'index')]
nChar <- ncol(tab)
chars <- seq_len(nChar)
minSteps <- apply(tab, 2, function(char)
TreeSearch:::MinimumSteps(decode[char])
)
for (ourFile in list.files('StartingTrees', pattern='*.nex')) {
trees <- read.nexus(paste0('StartingTrees/', ourFile))
for (i in seq_along(trees)) {
tree <- trees[[i]]
parsScore <- Fitch(tree, dataset)
#calculate number to go in exp() for branch lengths prior
expVal <- ncol(tab)/parsScore
obsSteps <- FitchSteps(tree, dataset)
#calculate Goloboff's unbiased measure of homoplasy for a given k (concavity constant) and data set
k <- 3
f <- (k+1)/(obsSteps+k+1+minSteps)
#rank characters by homoplasy values and then divide equally into a number of partitions
mat <- rbind(chars, f) #combine char no. and homoplasy value into one matrix
sortedMat <- mat[, order(f)] #sort columns by homoplasy (f) in ascending order
chunk <- round(prop * nChar) # number of characters per partition
partA <- sortedMat[1, 1:chunk]
partB <- sortedMat[1, (chunk+1) : (2*chunk)]
partC <- sortedMat[1, (2*chunk+1):(3*chunk)]
partD <- sortedMat[1, (3*chunk +1) : nChar]
mrBayesOutput <- c(mrBayesTemplate[seq_len(insertLine - 1)],
paste("charset partA =", paste(partA, collapse=' '), ";"),
paste("charset partB =", paste(partB, collapse=' '), ";"),
paste("charset partC =", paste(partC, collapse=' '), ";"),
paste("charset partD =", paste(partD, collapse=' '), ";"),
"",
"partition chartype=4: partA, partB, partC, partD;",
"set partition=chartype;",
"",
mrBayesTemplate[(insertLine + 1L):length(mrBayesTemplate)])
outputFile <- paste0(bayesFilesDir, '/', ourFile, '.', i, '.nex')
writeLines(mrBayesOutput, outputFile)
}
}
list.files('StartingTrees', pattern='*.nex')
for (ourFile in list.files('StartingTrees', pattern='*.nex')) {
trees <- read.nexus(paste0('StartingTrees/', ourFile))
for (i in seq_along(trees)) {
tree <- trees[[i]]
parsScore <- Fitch(tree, dataset)
#calculate number to go in exp() for branch lengths prior
expVal <- ncol(tab)/parsScore
obsSteps <- FitchSteps(tree, dataset)
#calculate Goloboff's unbiased measure of homoplasy for a given k (concavity constant) and data set
k <- 3
f <- (k+1)/(obsSteps+k+1+minSteps)
#rank characters by homoplasy values and then divide equally into a number of partitions
mat <- rbind(chars, f) #combine char no. and homoplasy value into one matrix
sortedMat <- mat[, order(f)] #sort columns by homoplasy (f) in ascending order
chunk <- round(prop * nChar) # number of characters per partition
partA <- sortedMat[1, 1:chunk]
partB <- sortedMat[1, (chunk+1) : (2*chunk)]
partC <- sortedMat[1, (2*chunk+1):(3*chunk)]
partD <- sortedMat[1, (3*chunk +1) : nChar]
mrBayesOutput <- c(mrBayesTemplate[seq_len(insertLine - 1)],
paste("charset partA =", paste(partA, collapse=' '), ";"),
paste("charset partB =", paste(partB, collapse=' '), ";"),
paste("charset partC =", paste(partC, collapse=' '), ";"),
paste("charset partD =", paste(partD, collapse=' '), ";"),
"",
"partition chartype=4: partA, partB, partC, partD;",
"set partition=chartype;",
"",
mrBayesTemplate[(insertLine + 1L):length(mrBayesTemplate)])
outputFile <- paste0(bayesFilesDir, '/', ourFile, '.', i, '.nex')
writeLines(mrBayesOutput, outputFile)
}
}
warnings()
View(dataset)
#calculate homoplasy indices from starting trees
require(TreeSearch)
require(ape)
require(phangorn)
# Define constants
nPart <- 4 #number of partitions
prop <- 1/nPart # proportion of characters per partition
insertionComment <- "INSERT PARTITIONS HERE"
bayesFilesDir <- 'MrBayes'
# Select dataset
datasetName <- "SCO"
rootDir <- paste0("C:/local/dxsb43/GitHub/Partitioning_Strategies/mutations/", datasetName)
setwd(rootDir)
mrBayesTemplateFile <- paste0(rootDir, '/', datasetName, '_TEMPLATE.nex')
dataset <- ReadAsPhyDat(mrBayesTemplateFile)
# Mr Bayes template
mrBayesTemplate <- readLines(mrBayesTemplateFile)
insertLine <- grep(insertionComment, mrBayesTemplate)
if (!dir.exists(bayesFilesDir)) dir.create(bayesFilesDir)
powerOf2 <- 2^(0:ncol(attr(dataset, "contrast"))) #contrast shows the possible permutations of
#the character states, i.e. 0, 1, 2, 3, 4, 5, {01}, {02} etc.
decode <- apply(attr(dataset, "contrast"), 1, function(r) #
sum(powerOf2[as.logical(r)])
)
tab <- t(vapply(dataset, I, dataset[[1]])) # translates lists of taxa and character data into matrix
tab <- tab[, attr(dataset, 'index')]
nChar <- ncol(tab)
chars <- seq_len(nChar)
minSteps <- apply(tab, 2, function(char)
TreeSearch:::MinimumSteps(decode[char])
)
for (ourFile in list.files('StartingTrees', pattern='*.nex')) {
trees <- read.nexus(paste0('StartingTrees/', ourFile))
for (i in seq_along(trees)) {
tree <- trees[[i]]
parsScore <- Fitch(tree, dataset)
#calculate number to go in exp() for branch lengths prior
expVal <- ncol(tab)/parsScore
obsSteps <- FitchSteps(tree, dataset)
#calculate Goloboff's unbiased measure of homoplasy for a given k (concavity constant) and data set
k <- 3
f <- (k+1)/(obsSteps+k+1+minSteps)
#rank characters by homoplasy values and then divide equally into a number of partitions
mat <- rbind(chars, f) #combine char no. and homoplasy value into one matrix
sortedMat <- mat[, order(f)] #sort columns by homoplasy (f) in ascending order
chunk <- round(prop * nChar) # number of characters per partition
partA <- sortedMat[1, 1:chunk]
partB <- sortedMat[1, (chunk+1) : (2*chunk)]
partC <- sortedMat[1, (2*chunk+1):(3*chunk)]
partD <- sortedMat[1, (3*chunk +1) : nChar]
mrBayesOutput <- c(mrBayesTemplate[seq_len(insertLine - 1)],
paste("charset partA =", paste(partA, collapse=' '), ";"),
paste("charset partB =", paste(partB, collapse=' '), ";"),
paste("charset partC =", paste(partC, collapse=' '), ";"),
paste("charset partD =", paste(partD, collapse=' '), ";"),
"",
"partition chartype=4: partA, partB, partC, partD;",
"set partition=chartype;",
"",
mrBayesTemplate[(insertLine + 1L):length(mrBayesTemplate)])
outputFile <- paste0(bayesFilesDir, '/', ourFile, '.', i, '.nex')
writeLines(mrBayesOutput, outputFile)
}
}
dataset <- dataset[, attr(dataset, 'index')]
for (ourFile in list.files('StartingTrees', pattern='*.nex')) {
trees <- read.nexus(paste0('StartingTrees/', ourFile))
for (i in seq_along(trees)) {
tree <- trees[[i]]
parsScore <- Fitch(tree, dataset)
#calculate number to go in exp() for branch lengths prior
expVal <- ncol(tab)/parsScore
obsSteps <- FitchSteps(tree, dataset)
#calculate Goloboff's unbiased measure of homoplasy for a given k (concavity constant) and data set
k <- 3
f <- (k+1)/(obsSteps+k+1+minSteps)
#rank characters by homoplasy values and then divide equally into a number of partitions
mat <- rbind(chars, f) #combine char no. and homoplasy value into one matrix
sortedMat <- mat[, order(f)] #sort columns by homoplasy (f) in ascending order
chunk <- round(prop * nChar) # number of characters per partition
partA <- sortedMat[1, 1:chunk]
partB <- sortedMat[1, (chunk+1) : (2*chunk)]
partC <- sortedMat[1, (2*chunk+1):(3*chunk)]
partD <- sortedMat[1, (3*chunk +1) : nChar]
mrBayesOutput <- c(mrBayesTemplate[seq_len(insertLine - 1)],
paste("charset partA =", paste(partA, collapse=' '), ";"),
paste("charset partB =", paste(partB, collapse=' '), ";"),
paste("charset partC =", paste(partC, collapse=' '), ";"),
paste("charset partD =", paste(partD, collapse=' '), ";"),
"",
"partition chartype=4: partA, partB, partC, partD;",
"set partition=chartype;",
"",
mrBayesTemplate[(insertLine + 1L):length(mrBayesTemplate)])
outputFile <- paste0(bayesFilesDir, '/', ourFile, '.', i, '.nex')
writeLines(mrBayesOutput, outputFile)
}
}
warnings()
dataset <- ReadAsPhyDat(mrBayesTemplateFile)
for (ourFile in list.files('StartingTrees', pattern='*.nex')) {
trees <- read.nexus(paste0('StartingTrees/', ourFile))
for (i in seq_along(trees)) {
tree <- trees[[i]]
parsScore <- Fitch(tree, tab)
#calculate number to go in exp() for branch lengths prior
expVal <- ncol(tab)/parsScore
obsSteps <- FitchSteps(tree, tab)
#calculate Goloboff's unbiased measure of homoplasy for a given k (concavity constant) and data set
k <- 3
f <- (k+1)/(obsSteps+k+1+minSteps)
#rank characters by homoplasy values and then divide equally into a number of partitions
mat <- rbind(chars, f) #combine char no. and homoplasy value into one matrix
sortedMat <- mat[, order(f)] #sort columns by homoplasy (f) in ascending order
chunk <- round(prop * nChar) # number of characters per partition
partA <- sortedMat[1, 1:chunk]
partB <- sortedMat[1, (chunk+1) : (2*chunk)]
partC <- sortedMat[1, (2*chunk+1):(3*chunk)]
partD <- sortedMat[1, (3*chunk +1) : nChar]
mrBayesOutput <- c(mrBayesTemplate[seq_len(insertLine - 1)],
paste("charset partA =", paste(partA, collapse=' '), ";"),
paste("charset partB =", paste(partB, collapse=' '), ";"),
paste("charset partC =", paste(partC, collapse=' '), ";"),
paste("charset partD =", paste(partD, collapse=' '), ";"),
"",
"partition chartype=4: partA, partB, partC, partD;",
"set partition=chartype;",
"",
mrBayesTemplate[(insertLine + 1L):length(mrBayesTemplate)])
outputFile <- paste0(bayesFilesDir, '/', ourFile, '.', i, '.nex')
writeLines(mrBayesOutput, outputFile)
}
}
for (ourFile in list.files('StartingTrees', pattern='*.nex')) {
trees <- read.nexus(paste0('StartingTrees/', ourFile))
for (i in seq_along(trees)) {
tree <- trees[[i]]
parsScore <- Fitch(tree, dataset)
#calculate number to go in exp() for branch lengths prior
expVal <- ncol(tab)/parsScore
obsSteps <- FitchSteps(tree, tab)
#calculate Goloboff's unbiased measure of homoplasy for a given k (concavity constant) and data set
k <- 3
f <- (k+1)/(obsSteps+k+1+minSteps)
#rank characters by homoplasy values and then divide equally into a number of partitions
mat <- rbind(chars, f) #combine char no. and homoplasy value into one matrix
sortedMat <- mat[, order(f)] #sort columns by homoplasy (f) in ascending order
chunk <- round(prop * nChar) # number of characters per partition
partA <- sortedMat[1, 1:chunk]
partB <- sortedMat[1, (chunk+1) : (2*chunk)]
partC <- sortedMat[1, (2*chunk+1):(3*chunk)]
partD <- sortedMat[1, (3*chunk +1) : nChar]
mrBayesOutput <- c(mrBayesTemplate[seq_len(insertLine - 1)],
paste("charset partA =", paste(partA, collapse=' '), ";"),
paste("charset partB =", paste(partB, collapse=' '), ";"),
paste("charset partC =", paste(partC, collapse=' '), ";"),
paste("charset partD =", paste(partD, collapse=' '), ";"),
"",
"partition chartype=4: partA, partB, partC, partD;",
"set partition=chartype;",
"",
mrBayesTemplate[(insertLine + 1L):length(mrBayesTemplate)])
outputFile <- paste0(bayesFilesDir, '/', ourFile, '.', i, '.nex')
writeLines(mrBayesOutput, outputFile)
}
}
dataset <- ReadAsPhyDat(mrBayesTemplateFile)
# Mr Bayes template
mrBayesTemplate <- readLines(mrBayesTemplateFile)
insertLine <- grep(insertionComment, mrBayesTemplate)
if (!dir.exists(bayesFilesDir)) dir.create(bayesFilesDir)
powerOf2 <- 2^(0:ncol(attr(dataset, "contrast"))) #contrast shows the possible permutations of
#the character states, i.e. 0, 1, 2, 3, 4, 5, {01}, {02} etc.
decode <- apply(attr(dataset, "contrast"), 1, function(r) #
sum(powerOf2[as.logical(r)])
)
tab <- t(vapply(dataset, I, dataset[[1]])) # translates lists of taxa and character data into matrix
tab <- tab[, attr(dataset, 'index')]
nChar <- ncol(tab)
chars <- seq_len(nChar)
minSteps <- apply(tab, 2, function(char)
TreeSearch:::MinimumSteps(decode[char])
)
for (ourFile in list.files('StartingTrees', pattern='*.nex')) {
trees <- read.nexus(paste0('StartingTrees/', ourFile))
for (i in seq_along(trees)) {
tree <- trees[[i]]
parsScore <- Fitch(tree, dataset)
#calculate number to go in exp() for branch lengths prior
expVal <- ncol(tab)/parsScore
obsSteps <- FitchSteps(tree, dataset)
#calculate Goloboff's unbiased measure of homoplasy for a given k (concavity constant) and data set
k <- 3
f <- (k+1)/(obsSteps+k+1+minSteps)
#rank characters by homoplasy values and then divide equally into a number of partitions
mat <- rbind(chars, f) #combine char no. and homoplasy value into one matrix
sortedMat <- mat[, order(f)] #sort columns by homoplasy (f) in ascending order
chunk <- round(prop * nChar) # number of characters per partition
partA <- sortedMat[1, 1:chunk]
partB <- sortedMat[1, (chunk+1) : (2*chunk)]
partC <- sortedMat[1, (2*chunk+1):(3*chunk)]
partD <- sortedMat[1, (3*chunk +1) : nChar]
mrBayesOutput <- c(mrBayesTemplate[seq_len(insertLine - 1)],
paste("charset partA =", paste(partA, collapse=' '), ";"),
paste("charset partB =", paste(partB, collapse=' '), ";"),
paste("charset partC =", paste(partC, collapse=' '), ";"),
paste("charset partD =", paste(partD, collapse=' '), ";"),
"",
"partition chartype=4: partA, partB, partC, partD;",
"set partition=chartype;",
"",
mrBayesTemplate[(insertLine + 1L):length(mrBayesTemplate)])
outputFile <- paste0(bayesFilesDir, '/', ourFile, '.', i, '.nex')
writeLines(mrBayesOutput, outputFile)
}
}
for (ourFile in list.files('StartingTrees', pattern='*.nex')) {
trees <- read.nexus(paste0('StartingTrees/', ourFile))
for (i in seq_along(trees)) {
tree <- trees[[i]]
parsScore <- Fitch(tree, dataset)
#calculate number to go in exp() for branch lengths prior
expVal <- ncol(tab)/parsScore
obsSteps <- FitchSteps(tree, dataset)
obsSteps <- obsSteps[, attr(dataset, 'index')]
#calculate Goloboff's unbiased measure of homoplasy for a given k (concavity constant) and data set
k <- 3
f <- (k+1)/(obsSteps+k+1+minSteps)
#rank characters by homoplasy values and then divide equally into a number of partitions
mat <- rbind(chars, f) #combine char no. and homoplasy value into one matrix
sortedMat <- mat[, order(f)] #sort columns by homoplasy (f) in ascending order
chunk <- round(prop * nChar) # number of characters per partition
partA <- sortedMat[1, 1:chunk]
partB <- sortedMat[1, (chunk+1) : (2*chunk)]
partC <- sortedMat[1, (2*chunk+1):(3*chunk)]
partD <- sortedMat[1, (3*chunk +1) : nChar]
mrBayesOutput <- c(mrBayesTemplate[seq_len(insertLine - 1)],
paste("charset partA =", paste(partA, collapse=' '), ";"),
paste("charset partB =", paste(partB, collapse=' '), ";"),
paste("charset partC =", paste(partC, collapse=' '), ";"),
paste("charset partD =", paste(partD, collapse=' '), ";"),
"",
"partition chartype=4: partA, partB, partC, partD;",
"set partition=chartype;",
"",
mrBayesTemplate[(insertLine + 1L):length(mrBayesTemplate)])
outputFile <- paste0(bayesFilesDir, '/', ourFile, '.', i, '.nex')
writeLines(mrBayesOutput, outputFile)
}
}
attr(dataset, 'index')
obsSteps <- obsSteps[attr(dataset, 'index')]
for (ourFile in list.files('StartingTrees', pattern='*.nex')) {
trees <- read.nexus(paste0('StartingTrees/', ourFile))
for (i in seq_along(trees)) {
tree <- trees[[i]]
parsScore <- Fitch(tree, dataset)
#calculate number to go in exp() for branch lengths prior
expVal <- ncol(tab)/parsScore
obsSteps <- FitchSteps(tree, dataset)
obsSteps <- obsSteps[attr(dataset, 'index')]
#calculate Goloboff's unbiased measure of homoplasy for a given k (concavity constant) and data set
k <- 3
f <- (k+1)/(obsSteps+k+1+minSteps)
#rank characters by homoplasy values and then divide equally into a number of partitions
mat <- rbind(chars, f) #combine char no. and homoplasy value into one matrix
sortedMat <- mat[, order(f)] #sort columns by homoplasy (f) in ascending order
chunk <- round(prop * nChar) # number of characters per partition
partA <- sortedMat[1, 1:chunk]
partB <- sortedMat[1, (chunk+1) : (2*chunk)]
partC <- sortedMat[1, (2*chunk+1):(3*chunk)]
partD <- sortedMat[1, (3*chunk +1) : nChar]
mrBayesOutput <- c(mrBayesTemplate[seq_len(insertLine - 1)],
paste("charset partA =", paste(partA, collapse=' '), ";"),
paste("charset partB =", paste(partB, collapse=' '), ";"),
paste("charset partC =", paste(partC, collapse=' '), ";"),
paste("charset partD =", paste(partD, collapse=' '), ";"),
"",
"partition chartype=4: partA, partB, partC, partD;",
"set partition=chartype;",
"",
mrBayesTemplate[(insertLine + 1L):length(mrBayesTemplate)])
outputFile <- paste0(bayesFilesDir, '/', ourFile, '.', i, '.nex')
writeLines(mrBayesOutput, outputFile)
}
}
